#!/usr/bin/env python3
import argparse
import glob
import os
import shutil

from google import genai
from dotenv import load_dotenv

from typing import List
from moviepy import VideoFileClip, concatenate_videoclips
import os
import time
from google.cloud import storage

from dotenv import load_dotenv
from google import genai
from google.genai import types

load_dotenv()

_api_key = os.getenv("API_KEY")
_project = os.getenv("GOOGLE_CLOUD_PROJECT")
_location = os.getenv("GOOGLE_CLOUD_LOCATION")

if not _api_key:
    raise RuntimeError("API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
if not _project or not _location:
    raise RuntimeError("GOOGLE_CLOUD_PROJECT / GOOGLE_CLOUD_LOCATION ì´ í•„ìš”í•©ë‹ˆë‹¤.")

client = genai.Client()

VIDEO_MODEL_ID = os.getenv("VIDEO_MODEL_ID", "veo-3.1-generate-001")


def _load_image(path: str) -> types.Image:
    if not os.path.exists(path):
        raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
    return types.Image.from_file(location=path)


def _download_gcs_uri(gcs_uri: str, local_path: str) -> None:
    """
    gs://bucket/path/to/file.mp4 í˜•íƒœì˜ URIë¥¼ ë¡œì»¬ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ.
    """
    if not gcs_uri.startswith("gs://"):
        raise ValueError(f"gs:// ë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” URI ì…ë‹ˆë‹¤: {gcs_uri}")

    without_scheme = gcs_uri[len("gs://") :]
    bucket_name, _, blob_path = without_scheme.partition("/")

    client = storage.Client()  # ADC ê¸°ë°˜ (gcloud auth application-default login ë“±)
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_path)

    os.makedirs(os.path.dirname(local_path), exist_ok=True)
    blob.download_to_filename(local_path)


def _generate_transition_vertex(
    img_a: str,
    img_b: str,
    out_path: str,
    prompt: str | None = None,
    duration_seconds: int = 4,
):
    """
    ë‘ ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•´ Veo 3.1ë¡œ í”„ë ˆì„ ë³´ê°„ ì˜ìƒ ìƒì„±.

    img_a       : ì‹œì‘ í”„ë ˆì„ ê²½ë¡œ
    img_b       : ë§ˆì§€ë§‰ í”„ë ˆì„ ê²½ë¡œ
    out_path    : ì €ì¥í•  mp4 ê²½ë¡œ
    prompt      : ì—†ìœ¼ë©´ ê¸°ë³¸ ë„ë¡œ ì£¼í–‰ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    duration_seconds : ìƒì„± ì˜ìƒ ê¸¸ì´(ì´ˆ). Veo ê¸°ë³¸ì€ 8ì´ˆì§€ë§Œ ì¤„ì—¬ë„ ë¨.
    """
    if prompt is None:
        prompt = (
            "A smooth driving roadview video transitioning from the first frame "
            "to the second frame, as if a camera is moving forward along the road."
        )

    print(f"  â–¶ Veo 3.1 ìš”ì²­: {os.path.basename(img_a)} â†’ {os.path.basename(img_b)}")

    # 1) ë¡œì»¬ ì´ë¯¸ì§€ë¥¼ Veoìš© Image ê°ì²´ë¡œ ë³€í™˜
    first_image = _load_image(img_a)
    last_image = _load_image(img_b)

    # 2) Veo 3.1ì— í”„ë ˆì„ ë³´ê°„ ìš”ì²­ (ì²« í”„ë ˆì„ + ë§ˆì§€ë§‰ í”„ë ˆì„)
    operation = client.models.generate_videos(
    model=VIDEO_MODEL_ID,
    prompt=prompt,
    image=first_image,
    config=types.GenerateVideosConfig(
        last_frame=last_image,
        duration_seconds=duration_seconds,
        aspect_ratio="16:9",
        resolution="720p",
        number_of_videos=1,
    ),
)


    # 3) Long-running operation í´ë§
        # 3) Long-running operation í´ë§
    while not operation.done:
        print("    â³ Veo ìƒì„± ì¤‘â€¦ (10ì´ˆ ëŒ€ê¸°)")
        # ì—¬ê¸°ì„œëŠ” ê·¸ëƒ¥ ê¸°ë‹¤ë¦¬ê¸°ë§Œ í•˜ê³ ,
        # operation ê°ì²´ëŠ” ê·¸ëŒ€ë¡œ ë‘”ë‹¤ (getìœ¼ë¡œ ë‹¤ì‹œ ê°€ì ¸ì˜¤ì§€ ì•ŠìŒ)
        time.sleep(10)

        # í•„ìš”í•˜ë©´ ìƒíƒœë¥¼ ë‹¤ì‹œ ë°›ì•„ì˜¤ê³  ì‹¶ì„ ë•ŒëŠ” name ê¸°ë°˜ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ê²Œ ì•ˆì „í•¨
        operation = client.operations.get(operation)

    # 4) ì‘ì—… ê²°ê³¼ / ì—ëŸ¬ í™•ì¸
    if getattr(operation, "response", None) is None:
        op_err = getattr(operation, "error", None)
        raise RuntimeError(f"Veo operationì´ ì‘ë‹µ ì—†ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. error={op_err!r}")

    if not getattr(operation.response, "generated_videos", None):
        raise RuntimeError(f"Veo ì‘ë‹µì— generated_videosê°€ ì—†ìŠµë‹ˆë‹¤. raw_response={operation.response!r}")

    video_info = operation.response.generated_videos[0]
    video_obj = video_info.video

    # 4-1) ìš°ì„  uri / gcs_uri ìˆëŠ”ì§€ ì‹œë„
    uri = getattr(video_obj, "uri", None) or getattr(video_obj, "gcs_uri", None)

    if uri:
        print(f"    ğŸ¯ Veo video uri: {uri}")

        if uri.startswith("gs://"):
            print(f"    â¬‡ï¸ GCS â†’ ë¡œì»¬ ë‹¤ìš´ë¡œë“œ: {out_path}")
            _download_gcs_uri(uri, out_path)
        elif uri.startswith("http://") or uri.startswith("https://"):
            import requests

            os.makedirs(os.path.dirname(out_path), exist_ok=True)
            print(f"    â¬‡ï¸ HTTP â†’ ë¡œì»¬ ë‹¤ìš´ë¡œë“œ: {out_path}")
            resp = requests.get(uri)
            resp.raise_for_status()
            with open(out_path, "wb") as f:
                f.write(resp.content)
        else:
            raise RuntimeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” URI í˜•ì‹ì…ë‹ˆë‹¤: {uri}")

        print(f"    âœ… Veo transition saved to {out_path}")
        return

    # 4-2) uriê°€ ì—†ë‹¤ë©´ â†’ ì¸ë¼ì¸ ë¹„ë””ì˜¤(video_bytes)ë¡œ ì˜¨ ê²½ìš° ì²˜ë¦¬
    print("    â„¹ï¸ URI ì—†ìŒ, ì¸ë¼ì¸ ë¹„ë””ì˜¤ ë°ì´í„°(video_bytes)ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    data = None

    # google-genaiì˜ Video ê°ì²´ê°€ video_bytes í•„ë“œë¥¼ ê°€ì§€ê³  ìˆìœ¼ë¯€ë¡œ ê±°ê¸°ì„œ êº¼ë‚¸ë‹¤
    if hasattr(video_obj, "video_bytes"):
        vb = video_obj.video_bytes
        # ë°”ë¡œ bytes/bytearrayì¸ ê²½ìš°
        if isinstance(vb, (bytes, bytearray)):
            data = vb
        # message ì•ˆì— data í•„ë“œê°€ ìˆëŠ” ê²½ìš° (ì˜ˆ: ByteString ê°™ì€ êµ¬ì¡°ì²´)
        elif hasattr(vb, "data"):
            data = vb.data
        # í˜¹ì‹œ bufferë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ê°ì‹¸ì ¸ ìˆì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ í•œ ë²ˆ ë” ì‹œë„
        elif hasattr(vb, "buffer"):
            data = vb.buffer

    if not data:
        # ì—¬ê¸°ì„œ ë‹¤ì‹œ íƒ€ì… í™•ì¸í•´ë³´ê³  ì‹¶ìœ¼ë©´ type(video_obj.video_bytes), dir(...) ì°ì–´ë³´ë©´ ë¨
        raise RuntimeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¹„ë””ì˜¤ ì‘ë‹µ í˜•ì‹ì…ë‹ˆë‹¤: {video_obj!r}")

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, "wb") as f:
        f.write(data)

    print(f"    âœ… Veo transition saved to {out_path}")


def _merge_videos(
    clip_paths: List[str],
    output_file: str,
    trim_last_frames: int = 7,
) -> None:
    """
    ì—¬ëŸ¬ mp4 í´ë¦½ì„ ì´ì–´ ë¶™ì—¬ í•˜ë‚˜ì˜ ì˜ìƒìœ¼ë¡œ í•©ì¹œë‹¤.
    ê° í´ë¦½ì˜ ë§ˆì§€ë§‰ `trim_last_frames` í”„ë ˆì„ì€ ì˜ë¼ë‚¸ë‹¤.

    :param clip_paths: ì´ì–´ ë¶™ì¼ ì˜ìƒ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ì•ì—ì„œë¶€í„° ìˆœì„œëŒ€ë¡œ)
    :param output_file: ìµœì¢… ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: "roadview.mp4")
    :param trim_last_frames: ê° í´ë¦½ì—ì„œ ë’¤ì—ì„œ ì œê±°í•  í”„ë ˆì„ ìˆ˜
    """
    clips = []
    used_fps = None

    for path in clip_paths:
        clip = VideoFileClip(path)

        # fps ê°€ì ¸ì˜¤ê¸° (ì²« ë²ˆì§¸ í´ë¦½ ê¸°ì¤€)
        fps = getattr(clip, "fps", None) or getattr(clip.reader, "fps", None)
        if used_fps is None:
            used_fps = fps

        if trim_last_frames > 0 and fps:
            trim_sec = trim_last_frames / fps
        else:
            trim_sec = 0.0

        # ë„ˆë¬´ ì§§ì€ í´ë¦½ì´ë©´ ìŠ¤í‚µ
        new_duration = max(0.0, clip.duration - trim_sec)
        if new_duration <= 0:
            print(f"âš ï¸ {path} : ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ì•„ì„œ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            clip.close()
            continue

        # 0 ~ new_duration êµ¬ê°„ë§Œ ì‚¬ìš©
        trimmed = clip.subclipped(0, new_duration)
        clips.append(trimmed)

    if not clips:
        raise RuntimeError("í•©ì¹  í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë‘ ìŠ¤í‚µë˜ì—ˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŒ)")

    print(f"ğŸ§µ {len(clips)}ê°œì˜ í´ë¦½ì„ ë³‘í•©í•©ë‹ˆë‹¤. (í´ë¦½ë‹¹ ë’¤ì—ì„œ {trim_last_frames}í”„ë ˆì„ ì œê±°)")

    final_clip = concatenate_videoclips(clips, method="compose")
    final_clip.write_videofile(
        output_file,
        fps=used_fps or 30,  # fps ì •ë³´ê°€ ì—†ìœ¼ë©´ 30ìœ¼ë¡œ
        codec="libx264",
        audio=False,
    )

    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    for c in clips:
        c.close()
    final_clip.close()


def interpolate_images(
        image_paths: str,
        out_file: str,
        out_dir: str,
        no_resume: bool = False
    ) -> None:
    clip_dir = os.path.join(out_dir, "clips")
    os.makedirs(clip_dir, exist_ok=True)

    clip_paths = []

    for i in range(len(image_paths) - 1):
        img_a = image_paths[i]
        img_b = image_paths[i + 1]

        clip_name = f"transition_{i+1:03d}.mp4"
        clip_path = os.path.join(clip_dir, clip_name)

        if not no_resume and os.path.exists(clip_path):
            print(f"â­  ì´ë¯¸ ì¡´ì¬, ìŠ¤í‚µ: {clip_path}")
            clip_paths.append(clip_path)
            continue

        print(f"ğŸ¬ ({i+1}/{len(image_paths)-1}) {os.path.basename(img_a)} â†’ {os.path.basename(img_b)}")
        _generate_transition_vertex(img_a, img_b, clip_path)
        clip_paths.append(clip_path)

    if not clip_paths:
        print("âŒ ìƒì„±ëœ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("ğŸ§µ í´ë¦½ ë³‘í•© ì¤‘â€¦")
    _merge_videos(clip_paths, os.path.join(out_dir, out_file))
    print("ğŸ‰ ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ:", os.path.join(out_dir, out_file))
    print(f"ğŸ§¹ ì¤‘ê°„ í´ë¦½ ì •ë¦¬: {clip_dir}")
    shutil.rmtree(clip_dir)


def main():
    load_dotenv()  # .env ë¡œë“œ

    parser = argparse.ArgumentParser(
        description="Streetview ì´ë¯¸ì§€ë“¤ì„ Veo(êµ¬ê¸€)ë¡œ ë³´ê°„í•´ì„œ ì˜ìƒìœ¼ë¡œ ë§Œë“œëŠ” ìŠ¤í¬ë¦½íŠ¸"
    )
    parser.add_argument(
        "--frames_dir",
        required=True,
        help="í”„ë ˆì„ ì´ë¯¸ì§€(jpg, png)ê°€ ë“¤ì–´ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ",
    )
    parser.add_argument(
        "--output",
        default="final.mp4",
        help="ìµœì¢… ì¶œë ¥ íŒŒì¼ ì´ë¦„ (ê¸°ë³¸: final.mp4)",
    )
    parser.add_argument(
        "--out_dir",
        default="demo_out",
        help="ì¤‘ê°„ transition í´ë¦½ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸: demo_out)",
    )
    parser.add_argument(
        "--no_resume",
        action="store_true",
        help="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í´ë¦½ì´ ìˆì–´ë„ ë¬´ì¡°ê±´ ë‹¤ì‹œ ìƒì„±",
    )

    args = parser.parse_args()
    interpolate_images(
        images=args.frames_dir,
        out_file=args.output,
        out_dir=args.out_dir,
        no_resume=args.no_resume,
    )
